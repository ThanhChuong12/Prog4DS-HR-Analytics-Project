{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca475b58",
   "metadata": {},
   "source": [
    "# HOMEWORK 2: NUMPY FOR DATA SCIENCE\n",
    "\n",
    "Họ tên: Lê Hà Thanh Chương\n",
    "\n",
    "MSSV: 23120195"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63f634e7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda7f06d",
   "metadata": {},
   "source": [
    "## Import các thư viện cần thiết"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9619ca74",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../src')\n",
    "from data_processing import process_hr_data, impute_missing, prepare_matrices, export_processed_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3d952a1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2eb6512",
   "metadata": {},
   "source": [
    "## Tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d0acea",
   "metadata": {},
   "source": [
    "Dựa trên những phát hiện quan trọng thu được ở bước khám phá dữ liệu (EDA) — đặc biệt là việc toàn bộ các biến được đọc dưới dạng chuỗi và sự tồn tại của nhiều biến ordinal — giai đoạn tiền xử lý được triển khai nhằm chuẩn hóa cấu trúc dữ liệu, đảm bảo mỗi biến phản ánh đúng bản chất định tính hoặc định lượng của nó, đồng thời thiết lập một cấu trúc dữ liệu nhất quán và tạo nền tảng cho các bước phân tích và mô hình hóa tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e2df99b",
   "metadata": {},
   "source": [
    "### Load raw data for preprocessing\n",
    "\n",
    "Trước hết, dữ liệu thô được tải lại từ tệp CSV và chuyển sang NumPy array để thuận tiện cho các bước tiền xử lý tiếp theo. Lưu ý rằng, dữ liệu đã được khám phá trong notebook 01_data_exploration, do đó bước này chỉ tập trung vào việc chuẩn bị dữ liệu cho pipeline preprocessing, bao gồm các thao tác chuẩn hóa kiểu dữ liệu, xử lý missing values và mapping ordinal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aaef57e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data loaded successfully!\n",
      "Shape: (19159, 14)\n",
      "Header: ['enrollee_id' 'city' 'city_development_index' 'gender'\n",
      " 'relevent_experience' 'enrolled_university' 'education_level'\n",
      " 'major_discipline' 'experience' 'company_size' 'company_type'\n",
      " 'last_new_job' 'training_hours' 'target']\n",
      "First row sample: ['8949' 'city_103' '0.92' 'Male' 'Has relevent experience' 'no_enrollment'\n",
      " 'Graduate' 'STEM' '>20' '' '' '1' '36' '1.0']\n"
     ]
    }
   ],
   "source": [
    "DATA_PATH = \"../data/raw/aug_train.csv\"\n",
    "\n",
    "# Load the dataset\n",
    "raw_data = np.genfromtxt(DATA_PATH, delimiter = \",\", dtype = str, encoding = \"utf-8\")\n",
    "\n",
    "print(\"Raw data loaded successfully!\")\n",
    "print(f\"Shape: {raw_data.shape}\")\n",
    "print(\"Header:\", raw_data[0])\n",
    "print(\"First row sample:\", raw_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07567122",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a926a",
   "metadata": {},
   "source": [
    "### Data Type Correction & Initial Preprocessing\n",
    "\n",
    "Sau khi dữ liệu thô được tải và chuyển sang dạng structured array (`raw_data`), bước tiếp theo là chuẩn hóa kiểu dữ liệu và thực hiện các thao tác preprocessing ban đầu nhằm đảm bảo tính nhất quán và phù hợp với các bước phân tích sau.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2b27d9",
   "metadata": {},
   "source": [
    "#### (A) Biến số (Numerical features)\n",
    "\n",
    "Hai biến mang bản chất liên tục được xử lý như sau:\n",
    "\n",
    "* `city_development_index` được chuyển sang kiểu `float`, phản ánh mức độ phát triển của thành phố nơi ứng viên cư trú.\n",
    "* `training_hours` cũng được lưu dưới dạng `float` để thuận tiện cho việc xử lý các giá trị missing, mặc dù bản chất dữ liệu là số nguyên.\n",
    "\n",
    "Việc giữ dạng float giúp đảm bảo khả năng áp dụng các phương pháp tính toán thống kê và scaling mà không làm mất thông tin do missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2bc5214",
   "metadata": {},
   "source": [
    "#### (B) Biến thứ tự (Ordinal features)\n",
    "\n",
    "Các biến ordinal trong dataset phản ánh quan hệ thứ bậc và do đó không thể xử lý như biến phân loại thông thường. Chúng được ánh xạ sang thang số nguyên theo các quy tắc nhất quán:\n",
    "\n",
    "* `experience`: các giá trị từ \"<1\" đến \">20\" được ánh xạ vào dãy số nguyên từ 0 đến 21.\n",
    "* `company_size`: chuẩn hóa các biểu diễn như \"10/49\" -> \"10-49\", sau đó mapping vào thang số nguyên phản ánh quy mô doanh nghiệp.\n",
    "* `last_new_job`: 'never', '1', …, '>4' được chuyển thành số nguyên thứ tự tương ứng từ 0 đến 5, phản ánh số năm kể từ công việc mới nhất.\n",
    "* `education_level`: các mức trình độ từ 'Primary School', 'High School', …, 'Phd' được mã hóa thành thang điểm thứ bậc 0 – 4.\n",
    "\n",
    "Các giá trị trống hoặc chuỗi rỗng trong các cột numerical và ordinal được chuyển thành `np.nan` để thuận tiện cho các bước xử lý missing values tiếp theo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c590d3",
   "metadata": {},
   "source": [
    "#### (C) Biến phân loại (Categorical nominal features)\n",
    "\n",
    "Nhóm các biến phân loại bao gồm:\n",
    "\n",
    "* `gender`, `relevent_experience`, `enrolled_university`, `major_discipline`, `company_type`, `city`\n",
    "\n",
    "Chúng được xử lý theo hai cơ chế khác nhau:\n",
    "\n",
    "1. Frequency Encoding cho biến `city`: Thay vì giữ nguyên dạng chuỗi, biến `city` được ánh xạ thành frequency encoding. Mỗi giá trị thành phố được thay bằng tần suất xuất hiện của nó trong dữ liệu, giúp giữ thông tin phân bố mà không tạo ra ma trận quá lớn khi one-hot encode làm giảm đáng kể số chiều của dữ liệu.\n",
    "\n",
    "2. One-hot Encoding cho các biến còn lại (`gender`, `relevent_experience`, `enrolled_university`, `major_discipline`, `company_type`)\n",
    "   * Giá trị trống (`''`) được thay bằng `'Unknown'`.\n",
    "   * Sau đó, áp dụng one-hot encoding để chuyển thành ma trận nhị phân, đảm bảo tính tương thích với các thuật toán học máy tuyến tính và phi tuyến."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0bbd2fb",
   "metadata": {},
   "source": [
    "#### Kết quả tiền xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6b961e1",
   "metadata": {},
   "source": [
    "Ví dụ kiểm tra sau khi mapping cho thấy tính chính xác của quá trình chuyển đổi:\n",
    "\n",
    "* `'>20' -> 21`, `'<1' -> 0` trong biến `experience`\n",
    "* các nhóm `company_size` được chuẩn hóa và mã hóa thành số nguyên\n",
    "* tần suất `city` được tính chính xác theo phân bố quan sát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55f1ade2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing complete.\n",
      "Keys available: dict_keys(['city_development_index', 'training_hours', 'experience', 'company_size', 'last_new_job', 'education_level', 'city_freq', 'gender_onehot', 'relevent_experience_onehot', 'enrolled_university_onehot', 'major_discipline_onehot', 'company_type_onehot', 'target'])\n",
      "\n",
      "Experience (Before mapping): ['>20' '15' '5' '<1' '>20']\n",
      "Experience (After mapping):  [21. 15.  5.  0. 21.]\n",
      "Company Size (After mapping): [nan  2. nan nan  2.]\n"
     ]
    }
   ],
   "source": [
    "processed_data = process_hr_data(raw_data)\n",
    "print(\"Preprocessing complete.\")\n",
    "print(\"Keys available:\", processed_data.keys())\n",
    "\n",
    "# Show some samples\n",
    "print(f\"\\nExperience (Before mapping): {raw_data[1:, 8][:5]}\")\n",
    "print(f\"Experience (After mapping):  {processed_data['experience'][:5]}\")\n",
    "print(f\"Company Size (After mapping): {processed_data['company_size'][:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a386dc8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4b79ec",
   "metadata": {},
   "source": [
    "### Missing Value Imputation\n",
    "\n",
    "Sau khi hoàn tất bước chuẩn hóa kiểu dữ liệu cho các biến numerical và ordinal, một số trường vẫn còn xuất hiện giá trị thiếu (*missing values*, biểu diễn dưới dạng `np.nan`). Việc xử lý missing values là yêu cầu thiết yếu nhằm đảm bảo tính toàn vẹn của dữ liệu, đồng thời duy trì khả năng áp dụng các phương pháp thống kê và mô hình học máy vốn không chấp nhận các giá trị trống."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54987c8",
   "metadata": {},
   "source": [
    "#### Chiến lược xử lý missing values\n",
    "\n",
    "Numerical và ordinal features (`city_development_index`, `training_hours`, `experience`, `company_size`): Các biến định lượng và thứ tự được xử lý bằng phương pháp thay thế giá trị thiếu bằng trung vị (median) của cột tương ứng. Phương pháp này giữ nguyên phân bố dữ liệu và hạn chế ảnh hưởng của các giá trị ngoại lai.\n",
    "\n",
    "Categorical nominal features: Các giá trị missing được giữ nguyên ở giai đoạn này; sẽ được xử lý sau nếu cần (ví dụ, khi áp dụng one-hot encoding hoặc target encoding).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7824968d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "city_development_index - missing values: 0\n",
      "training_hours - missing values: 0\n",
      "experience - missing values: 0\n",
      "company_size - missing values: 0\n",
      "last_new_job - missing values: 0\n",
      "education_level - missing values: 0\n"
     ]
    }
   ],
   "source": [
    "imputed_data = impute_missing(processed_data)\n",
    "\n",
    "# Check again if there are any NaNs\n",
    "cols_check = ['city_development_index', 'training_hours', 'experience', 'company_size', 'last_new_job', 'education_level']\n",
    "for col in cols_check:\n",
    "    n_missing = np.sum(np.isnan(imputed_data[col]))\n",
    "    print(f\"{col} - missing values: {n_missing}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27f530b0",
   "metadata": {},
   "source": [
    "Quá trình xử lý được kiểm tra bằng cách đếm lại số lượng `np.nan` trong những cột numerical và ordinal chủ chốt. Kết quả cho thấy toàn bộ các feature số đã được khử missing hoàn toàn, đảm bảo sẵn sàng cho các bước tiếp theo như chuẩn hóa (scaling), tạo ma trận đặc trưng và tách tập train/test."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a42842",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4c41693",
   "metadata": {},
   "source": [
    "### Feature Matrix Construction\n",
    "\n",
    "Sau khi dữ liệu đã được chuẩn hóa kiểu dữ liệu và xử lý đầy đủ các giá trị khuyết, bước tiếp theo trong quy trình tiền xử lý là xây dựng ma trận đặc trưng (*feature matrix*) phục vụ cho các thuật toán học máy.\n",
    "Mục tiêu của bước này là kết hợp có hệ thống toàn bộ các nhóm biến, bao gồm numerical, ordinal, frequency-encoded và one-hot encoded thành một cấu trúc dữ liệu duy nhất ($X$), nhất quán và tách biệt vector nhãn mục tiêu ($y$).\n",
    "\n",
    "Việc xây dựng ma trận đặc trưng được thực hiện thông qua hàm `prepare_matrices()` trong module `src/data_processing.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c1ae1c",
   "metadata": {},
   "source": [
    "#### Cơ chế hoạt động của hàm\n",
    "\n",
    "* Nhóm biến định lượng và thứ tự: Các biến như `city_development_index`, `training_hours`, `experience`, `company_size`, `last_new_job`, `education_level`, `city_freq`(frequency encoding) được ghép cột (`np.column_stack`) để tạo thành ma trận đặc trưng dạng số.\n",
    "* Nhóm biến One-hot: Tự động thu thập tất cả các ma trận con có hậu tố _onehot (ví dụ: `gender_onehot`, `major_discipline_onehot`). Sau đó toàn bộ ma trận này được ghép theo chiều cột.\n",
    "* Hợp nhất: Ghép toàn bộ thành ma trận $X$ có kích thước $N \\times M$, trong đó $N$ là số mẫu và $M$ là tổng số chiều đặc trưng. Kích thước thu được: n_samples × (7 + tổng số chiều one-hot)\n",
    "* Tách nhãn: Vector $y$ (`target`) được tách riêng phục vụ cho việc huấn luyện có giám sát."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e3399046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature matrix construction complete!\n",
      "X shape: (19158, 31)\n",
      "y shape: (19158,)\n"
     ]
    }
   ],
   "source": [
    "X, y = prepare_matrices(imputed_data)\n",
    "\n",
    "print(\"Feature matrix construction complete!\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3d255c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class distribution: {0: 14381, 1: 4777}\n"
     ]
    }
   ],
   "source": [
    "unique, counts = np.unique(y, return_counts=True) \n",
    "print(f\"Class distribution: {dict(zip(unique, counts))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73783ec7",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2793eb3",
   "metadata": {},
   "source": [
    "### Export Clean Dataset\n",
    "\n",
    "Sau khi hoàn tất tiền xử lý, chúng ta xuất dữ liệu ra hai định dạng:\n",
    "\n",
    "* `train_preprocessed.npy`: Dùng cho Notebook 03 (Modeling). Định dạng nhị phân của NumPy giúp load dữ liệu nhanh và giữ nguyên kiểu dữ liệu (không bị lỗi parsing).\n",
    "\n",
    "* `train_preprocessed.csv`: Dùng cho mục đích kiểm tra, báo cáo và bảo đảm tính tương thích với các notebook.\n",
    "\n",
    "Logic tạo header và xuất file được đóng gói trong hàm export_processed_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c8bb68",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Header columns: 32\n",
      "Matrix columns: 32\n",
      "CSV exported to: ../data/processed/train_preprocessed.csv\n",
      "NPY files exported to: ../data/processed\n"
     ]
    }
   ],
   "source": [
    "export_processed_data(X = X, y = y, raw_data = raw_data, imputed_data = imputed_data, output_dir=\"../data/processed\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
